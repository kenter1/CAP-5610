{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Implementation formulas from https://www.ics.uci.edu/~pjsadows/notes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = train_images_original.shape[0]\n",
    "m_test = test_images_original.shape[0]\n",
    "pixels = train_images_original.shape[1] * train_images_original.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I made the top left to always activate as a bias node\n",
    "train_images = train_images_original.reshape((60000, 28 * 28))\n",
    "train_images[:,0] = 255\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images_original.reshape((10000, 28 * 28))\n",
    "test_images[:,0] = 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[:,][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f42b6dd72e8>,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[:,][5].reshape(28,28)), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels_original)\n",
    "test_labels = to_categorical(test_labels_original)\n",
    "\n",
    "train_labels = train_labels.reshape(60000, 10)\n",
    "test_labels = test_labels.reshape(10000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeights(k, n):\n",
    "    return np.zeros(n*k).reshape(k,n)\n",
    "\n",
    "def generateRandomVector(k,n):\n",
    "    return np.random.rand(n*k).reshape(k,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 784), (784,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateWeights(10, 784).shape, generateRandomVector(10,784)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropSM(X,y,W,target,batch_size):\n",
    "    m = X.shape[0]\n",
    "    ds = y - target\n",
    "    dw = np.dot(ds.T, X)\n",
    "    \n",
    "    return dw/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z is a vector of n size = 10 (number of nodes in the last layer represents (0-9 activation nodes))\n",
    "def softmax(s):\n",
    "    y = np.exp(s) / np.sum(np.exp(s))\n",
    "    #print(\"{}\".format(y.sum()))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropSM(X, W, batch_size):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    y = []\n",
    "    #print(\"{} {}\".format(w.shape, X.shape))\n",
    "\n",
    "    for i in range(0,m):\n",
    "        s = (np.dot(W,X[i]))\n",
    "        a = softmax(s)\n",
    "        #print(\"{}\".format(a.sum()))\n",
    "        #print(\"{}\".format(a.shape))\n",
    "        y.append(a)\n",
    "        \n",
    "    \n",
    "    #a should be (10,m)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = forwardPropSM(test_images,trainedWeights, test_images.shape[0])\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = forwardPropSM2(test_images,trainedWeights, test_images.shape[0])\n",
    "#test_images.shape, trainedWeights.shape\n",
    "y[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does not work \n",
    "def forwardPropSM2(X, W, batch_size):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1] \n",
    "    #print(\"{} {}\".format(w.shape, X.shape))\n",
    "    s = (np.dot(W, X.T))\n",
    "    y = softmax(s)\n",
    "  \n",
    "    #a should be (10,m)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mini_batch_sm(epochs, lr, batch_size, X, t):\n",
    "    n = train_images.shape[1]\n",
    "    m = train_images.shape[0]\n",
    "    weights = generateWeights(10, 784)\n",
    "    for epoch in range(epochs):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        train_images_shuffled = X[shuffled_indices]\n",
    "        train_labels_shuffled = t[shuffled_indices]\n",
    "        for e in range(0,m,batch_size):    \n",
    "            xi = train_images_shuffled[e:e+batch_size]\n",
    "            ti = train_labels_shuffled[e:e+batch_size]\n",
    "\n",
    "            y = forwardPropSM(xi,weights,batch_size)\n",
    "            dw = backPropSM(xi,y,weights,ti,batch_size)\n",
    "            weights = weights - lr * dw  \n",
    "        print(\"Finished Epoch {}\".format(epoch))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 0\n",
      "Finished Epoch 1\n",
      "Finished Epoch 2\n",
      "Finished Epoch 3\n",
      "Finished Epoch 4\n",
      "CPU times: user 8.16 s, sys: 8.39 s, total: 16.6 s\n",
      "Wall time: 4.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 5\n",
    "lr = .5\n",
    "batch_size = 1000\n",
    "trainedWeights = train_mini_batch_sm(epochs,lr,batch_size,train_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedWeights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 9142/10000 : Accuracy 91.42%\n"
     ]
    }
   ],
   "source": [
    "predicted = forwardPropSM(test_images,trainedWeights, test_images.shape[0])\n",
    "df = pd.DataFrame(predicted)\n",
    "df = df.T\n",
    "pred_labels = df.idxmax()\n",
    "score = (pred_labels.values == test_labels_original).sum()\n",
    "print(\"Test Score {}/{} : Accuracy {}%\".format(score, test_labels_original.shape[0], 100*score/test_labels_original.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 54571/60000 : Accuracy 90.95166666666667%\n"
     ]
    }
   ],
   "source": [
    "predicted = forwardPropSM(train_images,trainedWeights, train_images.shape[0])\n",
    "df = pd.DataFrame(predicted)\n",
    "df = df.T\n",
    "pred_labels = df.idxmax()\n",
    "score = (pred_labels.values == train_labels_original).sum()\n",
    "print(\"Train Score {}/{} : Accuracy {}%\".format(score, train_labels_original.shape[0], 100*score/train_labels_original.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59990</th>\n",
       "      <th>59991</th>\n",
       "      <th>59992</th>\n",
       "      <th>59993</th>\n",
       "      <th>59994</th>\n",
       "      <th>59995</th>\n",
       "      <th>59996</th>\n",
       "      <th>59997</th>\n",
       "      <th>59998</th>\n",
       "      <th>59999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009365</td>\n",
       "      <td>9.986837e-01</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>2.327310e-07</td>\n",
       "      <td>2.983655e-04</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.065346</td>\n",
       "      <td>0.084899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000106</td>\n",
       "      <td>2.200571e-08</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.948561</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>9.895645e-01</td>\n",
       "      <td>5.155393e-07</td>\n",
       "      <td>0.976348</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.884079</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006853</td>\n",
       "      <td>3.223959e-05</td>\n",
       "      <td>0.015409</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.938432</td>\n",
       "      <td>9.606558e-04</td>\n",
       "      <td>1.269143e-03</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.941714</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.029512</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.010126</td>\n",
       "      <td>0.016478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.322166</td>\n",
       "      <td>6.614560e-05</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>6.886528e-03</td>\n",
       "      <td>9.907447e-01</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>0.983441</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.003436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.077014e-07</td>\n",
       "      <td>0.846312</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.084022</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>4.489413e-05</td>\n",
       "      <td>1.393986e-05</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.994972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.636064</td>\n",
       "      <td>1.093768e-03</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>2.458788e-04</td>\n",
       "      <td>7.911696e-04</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.910141</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.948163</td>\n",
       "      <td>0.048442</td>\n",
       "      <td>0.027639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001890</td>\n",
       "      <td>1.846577e-05</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1.387129e-04</td>\n",
       "      <td>5.352259e-07</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.036579</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.023578</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.853958</td>\n",
       "      <td>0.002972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.011257</td>\n",
       "      <td>2.128714e-05</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>9.834479e-05</td>\n",
       "      <td>1.251188e-05</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.164053</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.004078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009521</td>\n",
       "      <td>7.323498e-05</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.027463</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>1.699655e-03</td>\n",
       "      <td>6.198518e-03</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.045269</td>\n",
       "      <td>0.976004</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.728660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002756</td>\n",
       "      <td>1.104471e-05</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.886853</td>\n",
       "      <td>0.039125</td>\n",
       "      <td>3.606362e-04</td>\n",
       "      <td>6.706020e-04</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960277</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.783689</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.130850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 60000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0             1         2         3         4         5      \\\n",
       "0  0.009365  9.986837e-01  0.001781  0.000057  0.000030  0.001855   \n",
       "1  0.000106  2.200571e-08  0.000293  0.948561  0.000315  0.000011   \n",
       "2  0.006853  3.223959e-05  0.015409  0.017244  0.000057  0.938432   \n",
       "3  0.322166  6.614560e-05  0.065642  0.004064  0.000144  0.003469   \n",
       "4  0.000023  1.077014e-07  0.846312  0.000330  0.084022  0.000201   \n",
       "5  0.636064  1.093768e-03  0.002023  0.000618  0.000515  0.001846   \n",
       "6  0.001890  1.846577e-05  0.006889  0.000338  0.000136  0.000258   \n",
       "7  0.011257  2.128714e-05  0.005159  0.001085  0.020541  0.001440   \n",
       "8  0.009521  7.323498e-05  0.006072  0.027463  0.007388  0.013362   \n",
       "9  0.002756  1.104471e-05  0.050420  0.000239  0.886853  0.039125   \n",
       "\n",
       "          6             7         8         9        ...        59990  \\\n",
       "0  2.327310e-07  2.983655e-04  0.000013  0.000034    ...     0.000408   \n",
       "1  9.895645e-01  5.155393e-07  0.976348  0.000005    ...     0.000052   \n",
       "2  9.606558e-04  1.269143e-03  0.000952  0.000259    ...     0.000111   \n",
       "3  6.886528e-03  9.907447e-01  0.007617  0.000023    ...     0.000691   \n",
       "4  4.489413e-05  1.393986e-05  0.000227  0.994972    ...     0.009667   \n",
       "5  2.458788e-04  7.911696e-04  0.002611  0.001366    ...     0.002065   \n",
       "6  1.387129e-04  5.352259e-07  0.000676  0.001457    ...     0.000288   \n",
       "7  9.834479e-05  1.251188e-05  0.001368  0.000099    ...     0.021626   \n",
       "8  1.699655e-03  6.198518e-03  0.007336  0.001031    ...     0.004816   \n",
       "9  3.606362e-04  6.706020e-04  0.002852  0.000754    ...     0.960277   \n",
       "\n",
       "      59991     59992     59993     59994     59995     59996     59997  \\\n",
       "0  0.003934  0.002068  0.030015  0.000544  0.000140  0.000396  0.000553   \n",
       "1  0.000169  0.000600  0.000751  0.884079  0.000554  0.000027  0.000074   \n",
       "2  0.941714  0.000915  0.006601  0.029512  0.002342  0.000973  0.000012   \n",
       "3  0.000106  0.008532  0.016247  0.015261  0.015983  0.983441  0.010030   \n",
       "4  0.006845  0.009802  0.006898  0.006224  0.000216  0.000021  0.001931   \n",
       "5  0.000898  0.015525  0.910141  0.007852  0.004398  0.001734  0.948163   \n",
       "6  0.036579  0.000425  0.023578  0.001860  0.000028  0.000001  0.000087   \n",
       "7  0.000039  0.164053  0.000646  0.007186  0.000018  0.000004  0.001083   \n",
       "8  0.009510  0.014392  0.003526  0.045269  0.976004  0.013270  0.028520   \n",
       "9  0.000206  0.783689  0.001597  0.002212  0.000316  0.000132  0.009547   \n",
       "\n",
       "      59998     59999  \n",
       "0  0.065346  0.084899  \n",
       "1  0.000061  0.000316  \n",
       "2  0.010126  0.016478  \n",
       "3  0.002351  0.003436  \n",
       "4  0.014315  0.000673  \n",
       "5  0.048442  0.027639  \n",
       "6  0.853958  0.002972  \n",
       "7  0.001484  0.004078  \n",
       "8  0.000844  0.728660  \n",
       "9  0.003073  0.130850  \n",
       "\n",
       "[10 rows x 60000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
