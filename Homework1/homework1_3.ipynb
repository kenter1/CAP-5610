{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Implementation formulas from https://www.ics.uci.edu/~pjsadows/notes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = train_images_original.shape[0]\n",
    "m_test = test_images_original.shape[0]\n",
    "pixels = train_images_original.shape[1] * train_images_original.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I made the top left to always activate as a bias node\n",
    "train_images = train_images_original.reshape((60000, 28 * 28))\n",
    "train_images[:,0] = 255\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images_original.reshape((10000, 28 * 28))\n",
    "test_images[:,0] = 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[:,][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f9e9196b278>,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[:,][5].reshape(28,28)), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels_original)\n",
    "test_labels = to_categorical(test_labels_original)\n",
    "\n",
    "train_labels = train_labels.reshape(60000, 10)\n",
    "test_labels = test_labels.reshape(10000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeights(k, n):\n",
    "    return np.zeros(n*k).reshape(k,n)\n",
    "\n",
    "def generateRandomVector(k,n):\n",
    "    return np.random.rand(n*k).reshape(k,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 784), (784,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateWeights(10, 784).shape, generateRandomVector(10,784)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropSM(X,y,W,target,batch_size):\n",
    "    m = X.shape[0]\n",
    "    ds = y - target\n",
    "    dw = np.dot(ds.T, X)\n",
    "    \n",
    "    return dw/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z is a vector of n size = 10 (number of nodes in the last layer represents (0-9 activation nodes))\n",
    "def softmax(s):\n",
    "    y = np.exp(s) / np.sum(np.exp(s))\n",
    "    #print(\"{}\".format(y.sum()))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropSM(X, W, batch_size):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    y = []\n",
    "    #print(\"{} {}\".format(w.shape, X.shape))\n",
    "\n",
    "    for i in range(0,m):\n",
    "        s = (np.dot(W,X[i]))\n",
    "        a = softmax(s)\n",
    "        #print(\"{}\".format(a.sum()))\n",
    "        #print(\"{}\".format(a.shape))\n",
    "        y.append(a)\n",
    "        \n",
    "    \n",
    "    #a should be (10,m)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = forwardPropSM2(test_images,trainedWeights, test_images.shape[0])\n",
    "#y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does not work \n",
    "def forwardPropSM2(X, W, batch_size):\n",
    "    m = batch_size\n",
    "    n = X.shape[1] \n",
    "    #print(\"{} {}\".format(w.shape, X.shape))\n",
    "    s = (np.dot(X,W.T))\n",
    "    y = softmax(s)\n",
    "  \n",
    "    #a should be (10,m)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mini_batch_sm(epochs, lr, batch_size, X, t):\n",
    "    n = train_images.shape[1]\n",
    "    m = train_images.shape[0]\n",
    "    weights = generateWeights(10, 784)\n",
    "    for epoch in range(epochs):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        train_images_shuffled = X[shuffled_indices]\n",
    "        train_labels_shuffled = t[shuffled_indices]\n",
    "        for e in range(0,m,batch_size):    \n",
    "            xi = train_images_shuffled[e:e+batch_size]\n",
    "            ti = train_labels_shuffled[e:e+batch_size]\n",
    "\n",
    "            y = forwardPropSM(xi,weights,batch_size)\n",
    "            dw = backPropSM(xi,y,weights,ti,batch_size)\n",
    "            weights = weights - lr * dw  \n",
    "        print(\"Finished Epoch {}\".format(epoch))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 0\n",
      "Finished Epoch 1\n",
      "Finished Epoch 2\n",
      "Finished Epoch 3\n",
      "Finished Epoch 4\n",
      "CPU times: user 8.39 s, sys: 8.79 s, total: 17.2 s\n",
      "Wall time: 4.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 5\n",
    "lr = .5\n",
    "batch_size = 1000\n",
    "trainedWeights = train_mini_batch_sm(epochs,lr,batch_size,train_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedWeights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 9134/10000 : Accuracy 91.34%\n"
     ]
    }
   ],
   "source": [
    "predicted = forwardPropSM(test_images,trainedWeights, test_images.shape[0])\n",
    "df = pd.DataFrame(predicted)\n",
    "df = df.T\n",
    "pred_labels = df.idxmax()\n",
    "score = (pred_labels.values == test_labels_original).sum()\n",
    "print(\"Test Score {}/{} : Accuracy {}%\".format(score, test_labels_original.shape[0], 100*score/test_labels_original.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 54545/60000 : Accuracy 90.90833333333333%\n"
     ]
    }
   ],
   "source": [
    "predicted = forwardPropSM(train_images,trainedWeights, train_images.shape[0])\n",
    "df = pd.DataFrame(predicted)\n",
    "df = df.T\n",
    "pred_labels = df.idxmax()\n",
    "score = (pred_labels.values == train_labels_original).sum()\n",
    "print(\"Train Score {}/{} : Accuracy {}%\".format(score, train_labels_original.shape[0], 100*score/train_labels_original.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59990</th>\n",
       "      <th>59991</th>\n",
       "      <th>59992</th>\n",
       "      <th>59993</th>\n",
       "      <th>59994</th>\n",
       "      <th>59995</th>\n",
       "      <th>59996</th>\n",
       "      <th>59997</th>\n",
       "      <th>59998</th>\n",
       "      <th>59999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008730</td>\n",
       "      <td>9.986898e-01</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>2.321760e-07</td>\n",
       "      <td>3.338088e-04</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.029413</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.062785</td>\n",
       "      <td>0.095876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>2.272894e-08</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.955608</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>9.899067e-01</td>\n",
       "      <td>6.120227e-07</td>\n",
       "      <td>0.977362</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.892461</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005758</td>\n",
       "      <td>2.877895e-05</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.937359</td>\n",
       "      <td>9.196881e-04</td>\n",
       "      <td>1.291724e-03</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.934518</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.029176</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.018153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278689</td>\n",
       "      <td>5.956469e-05</td>\n",
       "      <td>0.061808</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>6.877198e-03</td>\n",
       "      <td>9.915969e-01</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.015096</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.984571</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.003533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.027733e-07</td>\n",
       "      <td>0.853724</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.085347</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>4.230530e-05</td>\n",
       "      <td>1.490356e-05</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.994921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.684332</td>\n",
       "      <td>1.101584e-03</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>2.528087e-04</td>\n",
       "      <td>1.006384e-03</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.913064</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.960638</td>\n",
       "      <td>0.046577</td>\n",
       "      <td>0.030989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001924</td>\n",
       "      <td>1.978341e-05</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.480202e-04</td>\n",
       "      <td>6.570255e-07</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.023790</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.861628</td>\n",
       "      <td>0.003361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010802</td>\n",
       "      <td>2.285043e-05</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>1.010974e-04</td>\n",
       "      <td>1.445120e-05</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.171202</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.004592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007267</td>\n",
       "      <td>6.732273e-05</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.021316</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>1.411439e-03</td>\n",
       "      <td>5.047510e-03</td>\n",
       "      <td>0.006354</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.013039</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.038705</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.020504</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.699875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002375</td>\n",
       "      <td>1.018333e-05</td>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.883868</td>\n",
       "      <td>0.040678</td>\n",
       "      <td>3.405305e-04</td>\n",
       "      <td>6.930477e-04</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957944</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.777034</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.142553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 60000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0             1         2         3         4         5      \\\n",
       "0  0.008730  9.986898e-01  0.001785  0.000057  0.000032  0.002092   \n",
       "1  0.000102  2.272894e-08  0.000294  0.955608  0.000342  0.000013   \n",
       "2  0.005758  2.877895e-05  0.013992  0.016804  0.000061  0.937359   \n",
       "3  0.278689  5.956469e-05  0.061808  0.003720  0.000147  0.003648   \n",
       "4  0.000020  1.027733e-07  0.853724  0.000300  0.085347  0.000205   \n",
       "5  0.684332  1.101584e-03  0.002065  0.000602  0.000537  0.002076   \n",
       "6  0.001924  1.978341e-05  0.007075  0.000335  0.000154  0.000302   \n",
       "7  0.010802  2.285043e-05  0.005357  0.001031  0.023195  0.001658   \n",
       "8  0.007267  6.732273e-05  0.005721  0.021316  0.006317  0.011969   \n",
       "9  0.002375  1.018333e-05  0.048179  0.000227  0.883868  0.040678   \n",
       "\n",
       "          6             7         8         9        ...        59990  \\\n",
       "0  2.321760e-07  3.338088e-04  0.000013  0.000035    ...     0.000438   \n",
       "1  9.899067e-01  6.120227e-07  0.977362  0.000005    ...     0.000055   \n",
       "2  9.196881e-04  1.291724e-03  0.000951  0.000239    ...     0.000111   \n",
       "3  6.877198e-03  9.915969e-01  0.007551  0.000023    ...     0.000666   \n",
       "4  4.230530e-05  1.490356e-05  0.000216  0.994921    ...     0.009913   \n",
       "5  2.528087e-04  1.006384e-03  0.002707  0.001408    ...     0.002280   \n",
       "6  1.480202e-04  6.570255e-07  0.000697  0.001566    ...     0.000321   \n",
       "7  1.010974e-04  1.445120e-05  0.001376  0.000106    ...     0.023660   \n",
       "8  1.411439e-03  5.047510e-03  0.006354  0.000958    ...     0.004611   \n",
       "9  3.405305e-04  6.930477e-04  0.002773  0.000739    ...     0.957944   \n",
       "\n",
       "      59991     59992     59993     59994     59995     59996     59997  \\\n",
       "0  0.004447  0.002154  0.029413  0.000544  0.000180  0.000433  0.000478   \n",
       "1  0.000195  0.000633  0.000754  0.892461  0.000751  0.000031  0.000066   \n",
       "2  0.934518  0.000904  0.005859  0.029176  0.002984  0.000960  0.000010   \n",
       "3  0.000118  0.008115  0.015096  0.014552  0.019429  0.984571  0.007681   \n",
       "4  0.007521  0.009777  0.006559  0.005929  0.000269  0.000022  0.001636   \n",
       "5  0.000992  0.016688  0.913064  0.007648  0.005936  0.002082  0.960638   \n",
       "6  0.042141  0.000452  0.023790  0.001879  0.000039  0.000002  0.000082   \n",
       "7  0.000045  0.171202  0.000639  0.006963  0.000025  0.000004  0.000998   \n",
       "8  0.009804  0.013039  0.003309  0.038705  0.969990  0.011761  0.020504   \n",
       "9  0.000219  0.777034  0.001517  0.002144  0.000398  0.000135  0.007906   \n",
       "\n",
       "      59998     59999  \n",
       "0  0.062785  0.095876  \n",
       "1  0.000059  0.000368  \n",
       "2  0.008674  0.018153  \n",
       "3  0.002157  0.003533  \n",
       "4  0.013033  0.000700  \n",
       "5  0.046577  0.030989  \n",
       "6  0.861628  0.003361  \n",
       "7  0.001471  0.004592  \n",
       "8  0.000789  0.699875  \n",
       "9  0.002825  0.142553  \n",
       "\n",
       "[10 rows x 60000 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
