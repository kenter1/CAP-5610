{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Implementation formulas from https://www.ics.uci.edu/~pjsadows/notes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = train_images_original.shape[0]\n",
    "m_test = test_images_original.shape[0]\n",
    "pixels = train_images_original.shape[1] * train_images_original.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I made the top left to always activate as a bias node\n",
    "train_images = train_images_original.reshape((60000, 28 * 28))\n",
    "train_images[:,0] = 255\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images_original.reshape((10000, 28 * 28))\n",
    "test_images[:,0] = 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[:,][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7fb8e8b2c240>,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[:,][5].reshape(28,28)), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels_original)\n",
    "test_labels = to_categorical(test_labels_original)\n",
    "\n",
    "train_labels = train_labels.reshape(60000, 10)\n",
    "test_labels = test_labels.reshape(10000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeights(k, n):\n",
    "    return np.zeros(n*k).reshape(k,n)\n",
    "\n",
    "def generateRandomVector(k,n):\n",
    "    return np.random.rand(n*k).reshape(k,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 784), (784,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateWeights(10, 784).shape, generateRandomVector(10,784)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropSM(X,y,W,target,batch_size):\n",
    "    m = X.shape[0]\n",
    "    ds = y - target\n",
    "    dw = np.dot(ds.T, X)\n",
    "    \n",
    "    return dw/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z is a vector of n size = 10 (number of nodes in the last layer represents (0-9 activation nodes))\n",
    "def softmax(s):\n",
    "    y = np.exp(s) / np.sum(np.exp(s))\n",
    "    #print(\"{}\".format(y.sum()))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropSM(X, W, batch_size):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    y = []\n",
    "    #print(\"{} {}\".format(w.shape, X.shape))\n",
    "\n",
    "    for i in range(0,m):\n",
    "        s = (np.dot(W,X[i]))\n",
    "        a = softmax(s)\n",
    "        #print(\"{}\".format(a.sum()))\n",
    "        #print(\"{}\".format(a.shape))\n",
    "        y.append(a)\n",
    "        \n",
    "    \n",
    "    #a should be (10,m)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.18034029e-04, 2.16724433e-07, 1.37261743e-04, 1.64065114e-03,\n",
       "       1.60910086e-05, 4.65887056e-05, 6.66842905e-07, 9.96620387e-01,\n",
       "       8.45614925e-05, 1.33554109e-03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = forwardPropSM(test_images,trainedWeights, test_images.shape[0])\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = forwardPropSM2(test_images,trainedWeights, test_images.shape[0])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does not work \n",
    "def forwardPropSM2(X, W, batch_size):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1] \n",
    "    #print(\"{} {}\".format(w.shape, X.shape))\n",
    "    s = (np.dot(X,W.T))\n",
    "    y = softmax(s)\n",
    "  \n",
    "    #a should be (10,m)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mini_batch_sm(epochs, lr, batch_size, X, t):\n",
    "    n = train_images.shape[1]\n",
    "    m = train_images.shape[0]\n",
    "    weights = generateWeights(10, 784)\n",
    "    for epoch in range(epochs):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        train_images_shuffled = X[shuffled_indices]\n",
    "        train_labels_shuffled = t[shuffled_indices]\n",
    "        for e in range(0,m,batch_size):    \n",
    "            xi = train_images_shuffled[e:e+batch_size]\n",
    "            ti = train_labels_shuffled[e:e+batch_size]\n",
    "\n",
    "            y = forwardPropSM(xi,weights,batch_size)\n",
    "            dw = backPropSM(xi,y,weights,ti,batch_size)\n",
    "            weights = weights - lr * dw  \n",
    "        print(\"Finished Epoch {}\".format(epoch))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 0\n",
      "Finished Epoch 1\n",
      "Finished Epoch 2\n",
      "Finished Epoch 3\n",
      "Finished Epoch 4\n",
      "CPU times: user 8.55 s, sys: 9.59 s, total: 18.1 s\n",
      "Wall time: 4.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 5\n",
    "lr = .5\n",
    "batch_size = 1000\n",
    "trainedWeights = train_mini_batch_sm(epochs,lr,batch_size,train_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedWeights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 9132/10000 : Accuracy 91.32%\n"
     ]
    }
   ],
   "source": [
    "predicted = forwardPropSM(test_images,trainedWeights, test_images.shape[0])\n",
    "df = pd.DataFrame(predicted)\n",
    "df = df.T\n",
    "pred_labels = df.idxmax()\n",
    "score = (pred_labels.values == test_labels_original).sum()\n",
    "print(\"Test Score {}/{} : Accuracy {}%\".format(score, test_labels_original.shape[0], 100*score/test_labels_original.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 54501/60000 : Accuracy 90.835%\n"
     ]
    }
   ],
   "source": [
    "predicted = forwardPropSM(train_images,trainedWeights, train_images.shape[0])\n",
    "df = pd.DataFrame(predicted)\n",
    "df = df.T\n",
    "pred_labels = df.idxmax()\n",
    "score = (pred_labels.values == train_labels_original).sum()\n",
    "print(\"Train Score {}/{} : Accuracy {}%\".format(score, train_labels_original.shape[0], 100*score/train_labels_original.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59990</th>\n",
       "      <th>59991</th>\n",
       "      <th>59992</th>\n",
       "      <th>59993</th>\n",
       "      <th>59994</th>\n",
       "      <th>59995</th>\n",
       "      <th>59996</th>\n",
       "      <th>59997</th>\n",
       "      <th>59998</th>\n",
       "      <th>59999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010014</td>\n",
       "      <td>9.988999e-01</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>1.943534e-07</td>\n",
       "      <td>2.741466e-04</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.060565</td>\n",
       "      <td>0.103369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>2.618404e-08</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.965264</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>9.916730e-01</td>\n",
       "      <td>6.368489e-07</td>\n",
       "      <td>0.980208</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.904961</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006490</td>\n",
       "      <td>3.171954e-05</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.945987</td>\n",
       "      <td>7.061545e-04</td>\n",
       "      <td>1.164669e-03</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.940578</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.021367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.364404</td>\n",
       "      <td>6.583809e-05</td>\n",
       "      <td>0.066808</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>5.765680e-03</td>\n",
       "      <td>9.937401e-01</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>0.988126</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.004164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.052311e-07</td>\n",
       "      <td>0.849866</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.089523</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>3.724713e-05</td>\n",
       "      <td>1.361137e-05</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.995381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011085</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.591585</td>\n",
       "      <td>8.923738e-04</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>1.841746e-04</td>\n",
       "      <td>5.755171e-04</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.901494</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.951846</td>\n",
       "      <td>0.040878</td>\n",
       "      <td>0.030804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002281</td>\n",
       "      <td>1.940262e-05</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>1.243403e-04</td>\n",
       "      <td>5.658792e-07</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.039821</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.026984</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.869403</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014655</td>\n",
       "      <td>2.391570e-05</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.024836</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>9.044583e-05</td>\n",
       "      <td>1.448506e-05</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.196420</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.005570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007873</td>\n",
       "      <td>5.763014e-05</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>1.130937e-03</td>\n",
       "      <td>3.687259e-03</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.033564</td>\n",
       "      <td>0.966088</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.683846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002530</td>\n",
       "      <td>9.052882e-06</td>\n",
       "      <td>0.046044</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.878762</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>2.878214e-04</td>\n",
       "      <td>5.290552e-04</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953770</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.752388</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.145716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 60000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0             1         2         3         4         5      \\\n",
       "0  0.010014  9.988999e-01  0.001779  0.000045  0.000032  0.001898   \n",
       "1  0.000142  2.618404e-08  0.000308  0.965264  0.000396  0.000014   \n",
       "2  0.006490  3.171954e-05  0.015358  0.013459  0.000059  0.945987   \n",
       "3  0.364404  6.583809e-05  0.066808  0.003127  0.000144  0.003537   \n",
       "4  0.000025  1.052311e-07  0.849866  0.000259  0.089523  0.000199   \n",
       "5  0.591585  8.923738e-04  0.001850  0.000427  0.000468  0.001603   \n",
       "6  0.002281  1.940262e-05  0.007329  0.000277  0.000156  0.000295   \n",
       "7  0.014655  2.391570e-05  0.005375  0.000949  0.024836  0.001716   \n",
       "8  0.007873  5.763014e-05  0.005284  0.016016  0.005624  0.009617   \n",
       "9  0.002530  9.052882e-06  0.046044  0.000178  0.878762  0.035135   \n",
       "\n",
       "          6             7         8         9        ...        59990  \\\n",
       "0  1.943534e-07  2.741466e-04  0.000012  0.000033    ...     0.000447   \n",
       "1  9.916730e-01  6.368489e-07  0.980208  0.000006    ...     0.000067   \n",
       "2  7.061545e-04  1.164669e-03  0.000789  0.000247    ...     0.000122   \n",
       "3  5.765680e-03  9.937401e-01  0.006634  0.000023    ...     0.000750   \n",
       "4  3.724713e-05  1.361137e-05  0.000202  0.995381    ...     0.011085   \n",
       "5  1.841746e-04  5.755171e-04  0.002182  0.001167    ...     0.002045   \n",
       "6  1.243403e-04  5.658792e-07  0.000621  0.001586    ...     0.000355   \n",
       "7  9.044583e-05  1.448506e-05  0.001290  0.000109    ...     0.027058   \n",
       "8  1.130937e-03  3.687259e-03  0.005597  0.000788    ...     0.004301   \n",
       "9  2.878214e-04  5.290552e-04  0.002465  0.000660    ...     0.953770   \n",
       "\n",
       "      59991     59992     59993     59994     59995     59996     59997  \\\n",
       "0  0.003881  0.002182  0.032598  0.000477  0.000198  0.000373  0.000576   \n",
       "1  0.000196  0.000751  0.000914  0.904961  0.000977  0.000033  0.000091   \n",
       "2  0.940578  0.000980  0.006958  0.025761  0.003492  0.000939  0.000012   \n",
       "3  0.000111  0.008924  0.017688  0.013183  0.023104  0.988126  0.010583   \n",
       "4  0.006672  0.010639  0.007624  0.005487  0.000309  0.000020  0.002171   \n",
       "5  0.000794  0.014925  0.901494  0.006353  0.005337  0.001338  0.951846   \n",
       "6  0.039821  0.000489  0.026984  0.001679  0.000044  0.000001  0.000103   \n",
       "7  0.000041  0.196420  0.000741  0.006639  0.000029  0.000004  0.001313   \n",
       "8  0.007718  0.012302  0.003374  0.033564  0.966088  0.009057  0.024024   \n",
       "9  0.000188  0.752388  0.001624  0.001897  0.000421  0.000110  0.009282   \n",
       "\n",
       "      59998     59999  \n",
       "0  0.060565  0.103369  \n",
       "1  0.000063  0.000468  \n",
       "2  0.008964  0.021367  \n",
       "3  0.002208  0.004164  \n",
       "4  0.013101  0.000827  \n",
       "5  0.040878  0.030804  \n",
       "6  0.869403  0.003868  \n",
       "7  0.001473  0.005570  \n",
       "8  0.000686  0.683846  \n",
       "9  0.002659  0.145716  \n",
       "\n",
       "[10 rows x 60000 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
